{
    "Key": "kafka_infographics",
    "Title": "Apache Kafka",
    "Subtitle": "An open-source distributed event streaming platform",
    "Avatar": "/img/logo/kafka.png",
    "Footer": "https://lkumarjain.blogspot.com/",
    "Color": "Red",
    "Articles": [{
            "Key": "article_1619513323561",
            "Color": "Purple",
            "SectionHeight": "150px",
            "Layout": "layout-3321",
            "Sections": [{
                    "Key": "article_1629513323562",
                    "Color": "Purple",
                    "Title": "Event",
                    "Subtitle": "Record / Message",
                    "Content": "Event (Record or Message) is just a thing that have happened with a description",
                    "Order": 0
                },
                {
                    "Key": "article_1619513412169",
                    "Color": "Purple",
                    "Title": "Topic",
                    "Subtitle": "Logical Composition",
                    "Content": "A logical composition of Partition having a logical name for producing and consuming records (Events) or a fundamental unit for organizing events​",
                    "Order": 1
                },
                {
                    "Key": "article_1619513438198",
                    "Color": "Purple",
                    "Content": "Multiple non-overlapping subsets of records with-in a topic (partitioning) to store records across machines. A Topic partition is totally ordered sequence of records​",
                    "Title": "Partition",
                    "Subtitle": "Sequence of Events",
                    "Order": 2
                },
                {
                    "Key": "article_1619513513128",
                    "Color": "Purple",
                    "Content": "Copies (replicates) of partition records across multiple nodes. Every partition has one leader and N-1 follower to provide fault-tolerance​",
                    "Title": "Replication",
                    "Order": 3,
                    "Subtitle": "Copies / Replicates"
                },
                {
                    "Key": "article_1619513622472",
                    "Color": "Purple",
                    "Content": "A computer instance or a container running Apache Kafka process to manage partitions, replication of these partitions​",
                    "Title": "Broker",
                    "Order": 4,
                    "Subtitle": "Computer Instance"
                },
                {
                    "Key": "article_1619513675278",
                    "Color": "Purple",
                    "Title": "Producer",
                    "Content": "Client application responsible for appending records to the log file of a Topic partition. Actual I/O is performed by the broker on behalf of producer client​",
                    "Order": 5,
                    "Subtitle": "Writer Client Application"
                }
            ]
        },
        {
            "Key": "article_1619513756954",
            "Color": "Indigo",
            "Subtitle": "Client Applications that are Read from Topic Partition​",
            "Title": "Con​sumer",
            "Order": 6,
            "SectionHeight": "150px",
            "Layout": "layout-3321",
            "Sections": [{
                    "Key": "article_1619513925607",
                    "Content": "A monotonically increasing number that serves as a unique identifier for a record in a partition. A consumer internally maintains an offset that points to the next record​",
                    "Title": "Offset",
                    "Subtitle": "Unique Identifier",
                    "Order": 7,
                    "Color": "Indigo"
                },
                {
                    "Key": "article_1619514009952",
                    "Type": "article",
                    "Color": "Indigo",
                    "Content": "Lag for a topic partition is expressed as number of offsets that are behind the head of partition.​",
                    "Title": "Lag",
                    "Subtitle": "#Events to be Consumed",
                    "Order": 8
                },
                {
                    "Key": "article_1619514113512",
                    "Color": "Indigo",
                    "Content": "A topic partition is an append-only ledger that may only be mutated by the Producer or Kafka itself. Consumer should commit its offsets frequently to avoid duplication​",
                    "Title": "Commit",
                    "Subtitle": "Consumed Event Identifier",
                    "Order": 9
                },
                {
                    "Key": "article_1619514191818",
                    "Color": "Indigo",
                    "Content": "Topic partitions are assigned to balance the assignments among all consumers in the logical group. All consumers work in a balanced mode​",
                    "Title": "Consumer Group​",
                    "Subtitle": "Logical Group",
                    "Order": 10
                },
                {
                    "Key": "article_1619514246338",
                    "Color": "Indigo",
                    "Content": "The optimal number of consumers should be equal or less then number of partitions to avoid any idle consumer​",
                    "Title": "Idle Consumer​",
                    "Order": 11,
                    "Subtitle": "#Consumers Across Group"
                },
                {
                    "Key": "article_1619514325614",
                    "Color": "Indigo",
                    "Content": "Consumers across groups are isolated and has their individual partition assignments and offsets​",
                    "Title": "Isolated Consumers​",
                    "Subtitle": "#Consumers Across Group",
                    "Order": 12
                }
            ]
        },
        {
            "Key": "article_1619514445488",
            "Color": "Teal",
            "Order": 13,
            "SectionHeight": "150px",
            "Layout": "layout-2221",
            "Sections": [{
                    "Key": "article_1619514536959",
                    "Color": "Teal",
                    "Order": 14,
                    "Title": "Real-Time Data Processing",
                    "Subtitle": "data to be processed as soon as it is available",
                    "Content": "Most modern applications require data to be processed as soon as it is available. This requires data processing solutions that are efficient, resilient, and scale easily."
                },
                {
                    "Key": "article_1619514599918",
                    "Color": "Teal",
                    "Order": 15,
                    "Title": "Activity Tracking",
                    "Content": "Kafka was originally developed for activity tracking to be used in LinkedIn. That implies each activity is published to central topics with one topic per activity type. ",
                    "Subtitle": "Originally developed for activity tracking"
                },
                {
                    "Key": "section_1628851758876",
                    "Color": "Teal",
                    "Title": "Dataflow Middleware",
                    "Content": "Kafka allows multiple applications to receive the same data at the same time. Using Kafka in the middle makes the pipeline more open and pluggable.",
                    "Subtitle": "Makes the pipeline more open and pluggable",
                    "Order": 2
                },
                {
                    "Key": "section_1628851805332",
                    "Color": "Teal",
                    "Title": "Complex Analysis",
                    "Content": "Kafka allows introspection of the most recent message or recent set of messages. Which allows us to detect outliers or anomalies but running complex analyses on the events.",
                    "Subtitle": "detect outliers or anomalies",
                    "Order": 3
                }
            ],
            "Title": "When To Use Kafka",
            "Subtitle": "Most common and strong use cases"
        },
        {
            "Key": "article_1628851880051",
            "SectionHeight": "150px",
            "Title": "When Not To Use Kafka",
            "Subtitle": "use cases where of Apache Kafka can be a overkill",
            "Order": 4,
            "Color": "Pink",
            "Sections": [{
                    "Key": "section_1628851975266",
                    "Color": "Pink",
                    "Title": "Few Messages Per Day",
                    "Content": "Kafka is designed to cope with the high load. We should make use of traditional message queues like RabbitMQ to process a small amount of (up to several thousand) messages per day as Kafka can be an overkill.",
                    "Subtitle": "designed to cope with the high load",
                    "Order": 0
                },
                {
                    "Key": "section_1628852486888",
                    "Color": "Pink",
                    "Title": "Need Response",
                    "Content": "Being a pub-sub (Publish-Subscribe) system Kafka does not offer the ability to provide acknowledgment back to the producer on message consumption by a consumer.",
                    "Subtitle": "Publish-Subscribe system ",
                    "Order": 1
                },
                {
                    "Key": "section_1628852532815",
                    "Color": "Pink",
                    "Title": "Long-Term Storage",
                    "Content": "Well, Kafka supports saving data during a specified retention period, but my recommendation is not to have this for too long as Kafka needs additional resources to manage a large amount of data.",
                    "Subtitle": "needs additional resources",
                    "Order": 2
                },
                {
                    "Key": "section_1628852592294",
                    "Color": "Pink",
                    "Title": "Ordered Processing",
                    "Subtitle": "requires a single consumer and single partition",
                    "Content": "Ordered processing of all the messages requires a single consumer and single partition as Kafka does not support message ordering across partitions.",
                    "Order": 3
                }
            ],
            "Layout": "layout-2221"
        },
        {
            "Key": "article_1619514672237",
            "Color": "Red",
            "Subtitle": "Shortcoming that may cause Developer Frustrations​",
            "Title": "Gotchas",
            "Order": 16,
            "SectionHeight": "150px",
            "Layout": "layout-2221",
            "Sections": [{
                    "Key": "article_1619514780934",
                    "Content": "The number of configuration parameters in Kafka can be overwhelming, not only for new commers but also seasoned pro​",
                    "Title": "Tunable Knobs​",
                    "Subtitle": "#Configuration Parameters",
                    "Order": 17,
                    "Color": "Red"
                },
                {
                    "Key": "article_1619514905610",
                    "Color": "Red",
                    "Content": "Kafka defaults tends to be optimized for the performance, and will need to be explicitly overridden on the client when safety is a critical objective​",
                    "Title": "Unsafe Defaults​",
                    "Subtitle": "Optimized for Performance",
                    "Order": 18
                },
                {
                    "Key": "article_1619514959277",
                    "Color": "Red",
                    "Content": "Kafka is capable of delivering messages over network as alarmingly fast rate, which can eventually cause a DoS attack if we are using an unchecked Kafka Consumer​",
                    "Title": "Back-Pressure​",
                    "Subtitle": "Alarmingly Fast Rate",
                    "Order": 19
                },
                {
                    "Key": "article_1619515032903",
                    "Color": "Red",
                    "Content": "Using older client with newer topic message formats, and vice versa, places extra load on the broker. This should be avoided whenever possible​",
                    "Title": "Format Conversion​",
                    "Subtitle": "Extra Load on the Broker",
                    "Order": 20
                }
            ]
        }
    ]
}